<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>AI on 云雾中的山-NubisMons</title>
        <link>https://blogbook.eu.org/categories/ai/</link>
        <description>Recent content in AI on 云雾中的山-NubisMons</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>云雾中的山-NubisMons</copyright>
        <lastBuildDate>Tue, 27 May 2025 16:28:50 +0800</lastBuildDate><atom:link href="https://blogbook.eu.org/categories/ai/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>统计学习方法</title>
        <link>https://blogbook.eu.org/p/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/</link>
        <pubDate>Fri, 16 May 2025 15:41:51 +0800</pubDate>
        
        <guid>https://blogbook.eu.org/p/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/</guid>
        <description>&lt;h2 id=&#34;这个是关于我看李航的统计学习方法的一些记录以防我看完就忘&#34;&gt;这个是关于我看李航的统计学习方法的一些记录,以防我看完就忘.
&lt;/h2&gt;&lt;h2 id=&#34;第一章统计学习及监督学习概论&#34;&gt;第一章统计学习及监督学习概论
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;什么是统计学习&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;就是基于数据建构一个概率统计模型并对数据进行一个预测.&lt;/p&gt;&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;统计学习的对象&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;其实就是数据,只不过这些数据的来源是多种多样的,比如文字,图像,视频,音频数据或者是它们的组合,关于数据的有一个基本假设就是迷人同类数据具有共同的性质的数据,比如说英文的文章,网页之类的.由于它们具有统计的规律性.所以可以用概率统计方法去处理它们.&lt;/p&gt;&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;统计学习方法的三要素&#34;&gt;统计学习方法的三要素
&lt;/h2&gt;&lt;p&gt;方法 = 模型+策略+算法&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;模型
就是学习什么样的模型.其实就是模型的假设空间所包含的所有函数的集合.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;策略
就是按照什么样的学习准则,也就是如何选择一个最佳模型.进而衍生出损失函数与风险函数预测的好坏..损失函数度量的是模型一次预测的好坏,风险函数度量平均意义下模型预测的好坏.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;算法
指的就是学习模型的具体计算方法.统计学习基于训练数据集,根据学习策略,从假设空间中选择最优模型.也就是寻找最优解.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;过拟合与模型选择&#34;&gt;过拟合与模型选择
&lt;/h2&gt;&lt;p&gt;当假设空间有不同的复杂度(例如:不同参数个数)的模型的时候,就要面临模型选择问题,我们当然是希望选择一个或者学习一个合适的模型.如果当假设空间中存在着一个&amp;quot;真&amp;quot;模型时,那么选择或者学习的模型应当要逼近这个真实的模型,也就是模型的参数向量与真模型的参数向量相近.如果是一味提高对训练数据的预测能力,所选模型的复杂度往往会比真实模型来得要高,这种现象就称之为过拟合.&lt;/p&gt;
&lt;h2 id=&#34;正则化与交叉验证&#34;&gt;正则化与交叉验证
&lt;/h2&gt;&lt;p&gt;交叉验证,随机将数据集分成三个部分,分别为训练集,验证集,测试集.训练集即为训练模型,验证集用于模型选择,测试用于对学习模型的评估.&lt;/p&gt;
&lt;h2 id=&#34;感知机&#34;&gt;感知机
&lt;/h2&gt;&lt;p&gt;感知机的这个东西起源很早,在1957年就已经提出了,但是它的分类模型在大多数时候泛化能力不强,但是原理简单,但是它是学习神经网络和深度学习的一个起点.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;感知机的模型
感知机的模型思想很简单,就是用于一个分类问题,也就是说将一堆东西,简单的分成两类,我这里举一个例子就是比如说,在一个广场上站着很多人,然后我们拿一条直线将男人和女人分开,这里可能有人会问,如果找不到怎么办?这个也就是说这个类别是线性不可分的,也就是说感知机模型并不适用.感知机模型的使用的一大前提就是这个东西是线性可分的才行.这个也就极大限制了感知机的使用场景.&lt;/p&gt;
&lt;p&gt;用数学的语言来说其实就是,有M个样本,每个样本对应着一个n维特征和一个二元输出,如下:
$(x_1^0,x_2^0,x_3^0,&amp;hellip;,x_n^0,y_0),(x_1^1,x_2^1,x_3^1,&amp;hellip;,x_n^1,y_1),&amp;hellip;,到n$&lt;/p&gt;
&lt;p&gt;我们的一个目标其实就是找到一个超平面,即:
$\theta_0+\theta_1x_1+&amp;hellip;+\theta_nx_n = 0$
让其中的一个类别都满足$\theta_0+\theta_1x_1+&amp;hellip;+\theta_nx_n&amp;gt;0$
或让其中一个$&amp;lt;0$,为了可以简化这种写法,我们其实可以加一个特征$x_0=1$,这样也就是$\sum_{i=0}^n\theta_ix_i=0$,其实用向量来表示就是$\theta \cdot x = 0$,而向量机的模型我们可以表示为, y = sign($\theta \cdot x$).
&lt;/p&gt;
$$
sign(x) = 
\begin{cases}
-1 &amp; x &lt; 0 \\
1 &amp; x \geq 0
\end{cases}
$$&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;感知机的损失函数
我们这个损失函数其实就是为了优化模型,感知机的损失函数它的优化目标就是期望使所有错误分类的样本到超平面的距离之和最小.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>图像到图像的翻译的具有自适应实例归一化的无监督生成注意网络</title>
        <link>https://blogbook.eu.org/p/%E5%9B%BE%E5%83%8F%E5%88%B0%E5%9B%BE%E5%83%8F%E7%9A%84%E7%BF%BB%E8%AF%91%E7%9A%84%E5%85%B7%E6%9C%89%E8%87%AA%E9%80%82%E5%BA%94%E5%AE%9E%E4%BE%8B%E5%BD%92%E4%B8%80%E5%8C%96%E7%9A%84%E6%97%A0%E7%9B%91%E7%9D%A3%E7%94%9F%E6%88%90%E6%B3%A8%E6%84%8F%E7%BD%91%E7%BB%9C/</link>
        <pubDate>Sun, 26 Mar 2023 20:18:58 +0000</pubDate>
        
        <guid>https://blogbook.eu.org/p/%E5%9B%BE%E5%83%8F%E5%88%B0%E5%9B%BE%E5%83%8F%E7%9A%84%E7%BF%BB%E8%AF%91%E7%9A%84%E5%85%B7%E6%9C%89%E8%87%AA%E9%80%82%E5%BA%94%E5%AE%9E%E4%BE%8B%E5%BD%92%E4%B8%80%E5%8C%96%E7%9A%84%E6%97%A0%E7%9B%91%E7%9D%A3%E7%94%9F%E6%88%90%E6%B3%A8%E6%84%8F%E7%BD%91%E7%BB%9C/</guid>
        <description>&lt;h2 id=&#34;本文仅记录一些我的学习这篇论文记录&#34;&gt;本文仅记录一些我的学习这篇论文记录
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;什么是卷积神经网络&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;卷积这个东西有三层含义:
1.第一个就是稳定的输出和不稳定的输入求其的系统存量
2.周围像素点是如何影响的
3.一个像素点的试探,就是起到一个过滤器的作用把我们需要的特征提取出来&lt;/p&gt;&lt;/blockquote&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;什么是神经网络&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;1.旧的感知机无法实现异或运算,感知机与现有计算机的区别,它优势在哪里,感知机是一种分类工具,用随机梯度下降法,用数据去进行一个训练把分类的标准进行一个调整.感知机有标准能判断,在一个n维的情况下进行判别,使用n-1维去判断(就是进行一个分割,就是一个立体的东西进行一个切割,我们就要用到一个面,而一个面进行切割我们就要用到一个一根线,就是说一个n维的东西就行切割我们要用n-1维的去切割分类)还有就是只能进行线性分割.感知机使用一个统一模板对东西进行分类,就是一个线性函数加一个激活函数(判断函数),
具体的表达 $t=f(\sum=w_ix_i+b=f(w^Tx))$
感知机的缺陷就是没有办法处理异或问题,因为异或问题没有办法进行线性可分
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/ljy18/blogimg/6c82077a4f1fe1f3b0f3a0ca821e3ea.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;6c82077a4f1fe1f3b0f3a0ca821e3ea&#34;
	
	
&gt;
为了解决这个问题提出多层神经网络,通过多个感知机进行解决
盖尔定理进行如果在低维的情况下想要进行线性可分比较困难,那我们可以进行一个升维进行&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;测试&#34;&gt;测试
&lt;/h2&gt;</description>
        </item>
        <item>
        <title>卷积公式</title>
        <link>https://blogbook.eu.org/p/%E5%8D%B7%E7%A7%AF%E5%85%AC%E5%BC%8F/</link>
        <pubDate>Sun, 11 Sep 2022 18:50:55 +0000</pubDate>
        
        <guid>https://blogbook.eu.org/p/%E5%8D%B7%E7%A7%AF%E5%85%AC%E5%BC%8F/</guid>
        <description>&lt;h2 id=&#34;前期提示&#34;&gt;前期提示
&lt;/h2&gt;&lt;p&gt;以下东西纯属个人消化&lt;/p&gt;
&lt;h2 id=&#34;缘由&#34;&gt;缘由
&lt;/h2&gt;&lt;p&gt;首先说一下写这个东西的原因:就是这个卷积公式的理解一直都是我学习信号与系统的拦路虎,一直无法理解这个是什么东西,终于在今晚弄懂了我滴天啊!&lt;/p&gt;
&lt;h2 id=&#34;卷积公式的形式&#34;&gt;卷积公式的形式
&lt;/h2&gt;&lt;p&gt;首先来看一下这个卷积公式的形式
&lt;strong&gt;积分形式&lt;/strong&gt;&lt;/p&gt;
$$(f*g)(n)=\int^{+\infty}_{-\infty}f(\tau)g(n-\tau)d{\tau}$$&lt;p&gt;&lt;strong&gt;离散形式&lt;/strong&gt;&lt;/p&gt;
$$(f*g)(n)=\sum^{+\infty}_{-\infty}f(\tau)g(n-\tau)$$&lt;h2 id=&#34;翻卷&#34;&gt;翻卷
&lt;/h2&gt;&lt;p&gt;其实吧,我一直没办法就是为什么那个$f(\tau)$要乘于一个负的$g(n-\tau)$,我认为关键就是理解的这个$-\tau$,理解了这个就理解了整个公式.&lt;/p&gt;
&lt;h2 id=&#34;举一个例子&#34;&gt;举一个例子
&lt;/h2&gt;&lt;h3 id=&#34;扔石头&#34;&gt;扔石头
&lt;/h3&gt;&lt;p&gt;往水面仍石头,我们把水面的反应当成的一个冲击反应,我们在t=0时,扔下一个石头会激起一个h(0)的波纹,但是水面不会立刻平静,随着时间的流逝，波纹幅度会越来越小，在t=1时刻，幅度衰减为h(1), 在t=2时刻，幅度衰减为h(2)……直到一段时间后，水面重复归于平静.&lt;/p&gt;
&lt;p&gt;从时间轴上来看，我们只在t=0时刻丢了一块石头，其它时刻并没有做任何事，但在t=1,2….时刻，水面是不平静的，这是因为过去（t=0时刻）的作用一直持续到了现在。那么，问题来了：如果我们在t=1时刻也丢入一块石子呢？此时t=0时刻的影响还没有消失（水面还没有恢复平静）新的石子又丢进来了，那么现在激起的波浪有多高呢？答案是当前激起的波浪与t=0时刻残余的影响的叠加。那么t=0时刻对t=1时刻的残余影响有多大呢？为了便于说明，接下来我们作一下两个假设：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1．  水面对于“单位石块”的响应是固定的.&lt;/li&gt;
&lt;li&gt;2．  丢一个两倍于的“单位石块”的石块激起的波纹高度是丢一个石块的两倍（即系统满足线性叠加原理）现在我们来计算每一时刻的波浪有多高:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那么我们一个时刻就扔一个石头,t=0,t=1,t=2时,以此类推.那么我们来算一下每个时水面的反应:&lt;/p&gt;
&lt;p&gt;y为水面的反应,x为石子,h为水面的激起波澜的函数&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;t=0时:
y(0)=x(0)*h(0)//t0时刻一个石子在h0时刻激起y0&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;t=1时
y(1)=x(1)*h(0)+x(0)*h(1)//这个就是当前石子激起h(0),和之前那个x(0)那个的残余的叠加&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;t=2时:
y(2)=x(2)*h(0)+x(1)*h(1)+x(0)*h(2)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以此类推&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;t=n 时:
y(n)=x(n)*h(0)+x(n-1)*h(1)+x(n-2)*h(2)+&amp;hellip;+x(0)*h(n)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;推到这一步把用累加符号弄在一起你会惊讶的发现,我擦这个不就是说这个吗?
$\sum_{i=0}^nx(i)&lt;em&gt;h(n-i)$是不是很是相像$(f&lt;/em&gt;g)(n)=\sum^{+\infty}_{-\infty}f(\tau)g(n-\tau)$.这就是离散卷积的公式了理解了上面的问题，下面我们来看看“翻转”是怎么回事：当我们每次要丢石子时，站在当前的时间点，系统的对我们的回应都是h(0),时间轴之后的（h(1),h(2)&amp;hellip;..）都是对未来的影响。而整体的回应要加上过去对于现在的残余影响。现在我们来观察t=4这个时刻.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;站在t=0时刻看他对于未来（t=4）时刻(从现在往后4秒)的影响，可见是x(0)*h(4)&lt;/li&gt;
&lt;li&gt;站在t=1时刻看他对于未来（t=4）时刻的影响(从现在往后3秒)，可见是x(1)*h(3)&lt;/li&gt;
&lt;li&gt;站在t=2时刻看他对于未来（t=4）时刻的影响(从现在往后2秒)，可见是x(2)*h(2)&lt;/li&gt;
&lt;li&gt;站在t=3时刻看他对于未来（t=4）时刻的影响(从现在往后1秒)，可见是x(3)*h(1)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;图示:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Ljy18/blogimg/main/convolution.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;示意图&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;你将第一幅和第三幅对应的乘起来是不是就是那个
y(4)=x(4)*h(0)+x(3)*h(1)+x(2)*h(2)+x(1)*h(3)+x(0)*h(4)&lt;/p&gt;
&lt;h2 id=&#34;结论所以所谓的翻转只是因为你站立的现在是过去的未来所谓卷积其实就是过去对现在影响的叠加&#34;&gt;结论:所以所谓的翻转只是因为你站立的现在是过去的未来,所谓卷积其实就是过去对现在影响的叠加.
&lt;/h2&gt;</description>
        </item>
        
    </channel>
</rss>
