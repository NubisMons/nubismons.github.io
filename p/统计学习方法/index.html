<!DOCTYPE html>
<html lang="zh-cn" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content="这个是关于我看李航的统计学习方法的一些记录,以防我看完就忘. 第一章统计学习及监督学习概论 什么是统计学习\n就是基于数据建构一个概率统计模型并对数据进行一个预测.\n统计学习的对象\n其实就是数据,只不过这些数据的来源是多种多样的,比如文字,图像,视频,音频数据或者是它们的组合,关于数据的有一个基本假设就是迷人同类数据具有共同的性质的数据,比如说英文的文章,网页之类的.由于它们具有统计的规律性.所以可以用概率统计方法去处理它们.\n">
<title>统计学习方法</title>

<link rel='canonical' href='https://blogbook.eu.org/p/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/'>

<link rel="stylesheet" href="/scss/style.min.9dd6f25885002759c6b8702ee8bd063a2f1d77080acd4e4ba3ae8c31e6ce062a.css"><meta property='og:title' content="统计学习方法">
<meta property='og:description' content="这个是关于我看李航的统计学习方法的一些记录,以防我看完就忘. 第一章统计学习及监督学习概论 什么是统计学习\n就是基于数据建构一个概率统计模型并对数据进行一个预测.\n统计学习的对象\n其实就是数据,只不过这些数据的来源是多种多样的,比如文字,图像,视频,音频数据或者是它们的组合,关于数据的有一个基本假设就是迷人同类数据具有共同的性质的数据,比如说英文的文章,网页之类的.由于它们具有统计的规律性.所以可以用概率统计方法去处理它们.\n">
<meta property='og:url' content='https://blogbook.eu.org/p/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/'>
<meta property='og:site_name' content='云雾中的山-NubisMons'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:published_time' content='2025-05-16T15:41:51&#43;08:00'/><meta property='article:modified_time' content='2025-06-16T12:55:49&#43;08:00'/>
<meta name="twitter:title" content="统计学习方法">
<meta name="twitter:description" content="这个是关于我看李航的统计学习方法的一些记录,以防我看完就忘. 第一章统计学习及监督学习概论 什么是统计学习\n就是基于数据建构一个概率统计模型并对数据进行一个预测.\n统计学习的对象\n其实就是数据,只不过这些数据的来源是多种多样的,比如文字,图像,视频,音频数据或者是它们的组合,关于数据的有一个基本假设就是迷人同类数据具有共同的性质的数据,比如说英文的文章,网页之类的.由于它们具有统计的规律性.所以可以用概率统计方法去处理它们.\n">
    <link rel="shortcut icon" href="/favicon.ico" />

<script>
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']]
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    }
  };
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="切换菜单">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu_cac027ab500e5a86.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
                    <span class="emoji">♾️</span>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">云雾中的山-NubisMons</a></h1>
            <h2 class="site-description">欢迎来到我的博客</h2>
        </div>
    </header><ol class="menu-social">
            
                <li>
                    <a 
                        href='https://space.bilibili.com/290719760'
                        target="_blank"
                        
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.0.0-beta2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M488.6 104.1C505.3 122.2 513 143.8 511.9 169.8V372.2C511.5 398.6 502.7 420.3 485.4 437.3C468.2 454.3 446.3 463.2 419.9 464H92.02C65.57 463.2 43.81 454.2 26.74 436.8C9.682 419.4 .7667 396.5 0 368.2V169.8C.7667 143.8 9.682 122.2 26.74 104.1C43.81 87.75 65.57 78.77 92.02 78H121.4L96.05 52.19C90.3 46.46 87.42 39.19 87.42 30.4C87.42 21.6 90.3 14.34 96.05 8.603C101.8 2.868 109.1 0 117.9 0C126.7 0 134 2.868 139.8 8.603L213.1 78H301.1L375.6 8.603C381.7 2.868 389.2 0 398 0C406.8 0 414.1 2.868 419.9 8.603C425.6 14.34 428.5 21.6 428.5 30.4C428.5 39.19 425.6 46.46 419.9 52.19L394.6 78L423.9 78C450.3 78.77 471.9 87.75 488.6 104.1H488.6zM449.8 173.8C449.4 164.2 446.1 156.4 439.1 150.3C433.9 144.2 425.1 140.9 416.4 140.5H96.05C86.46 140.9 78.6 144.2 72.47 150.3C66.33 156.4 63.07 164.2 62.69 173.8V368.2C62.69 377.4 65.95 385.2 72.47 391.7C78.99 398.2 86.85 401.5 96.05 401.5H416.4C425.6 401.5 433.4 398.2 439.7 391.7C446 385.2 449.4 377.4 449.8 368.2L449.8 173.8zM185.5 216.5C191.8 222.8 195.2 230.6 195.6 239.7V273C195.2 282.2 191.9 289.9 185.8 296.2C179.6 302.5 171.8 305.7 162.2 305.7C152.6 305.7 144.7 302.5 138.6 296.2C132.5 289.9 129.2 282.2 128.8 273V239.7C129.2 230.6 132.6 222.8 138.9 216.5C145.2 210.2 152.1 206.9 162.2 206.5C171.4 206.9 179.2 210.2 185.5 216.5H185.5zM377 216.5C383.3 222.8 386.7 230.6 387.1 239.7V273C386.7 282.2 383.4 289.9 377.3 296.2C371.2 302.5 363.3 305.7 353.7 305.7C344.1 305.7 336.3 302.5 330.1 296.2C323.1 289.9 320.7 282.2 320.4 273V239.7C320.7 230.6 324.1 222.8 330.4 216.5C336.7 210.2 344.5 206.9 353.7 206.5C362.9 206.9 370.7 210.2 377 216.5H377z"/></svg>
                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://github.com/NubisMons'
                        target="_blank"
                        title="GitHub"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" />
</svg>



                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://twitter.com'
                        target="_blank"
                        title="Twitter"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M22 4.01c-1 .49 -1.98 .689 -3 .99c-1.121 -1.265 -2.783 -1.335 -4.38 -.737s-2.643 2.06 -2.62 3.737v1c-3.245 .083 -6.135 -1.395 -8 -4c0 0 -4.182 7.433 4 11c-1.872 1.247 -3.739 2.088 -6 2c3.308 1.803 6.913 2.423 10.034 1.517c3.58 -1.04 6.522 -3.723 7.651 -7.742a13.84 13.84 0 0 0 .497 -3.753c-.002 -.249 1.51 -2.772 1.818 -4.013z" />
</svg>



                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>Home</span>
            </a>
        </li>
        
        
        <li >
            <a href='/about/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="7" r="4" />
  <path d="M6 21v-2a4 4 0 0 1 4 -4h4a4 4 0 0 1 4 4v2" />
</svg>



                
                <span>About</span>
            </a>
        </li>
        
        
        <li >
            <a href='/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>Archives</span>
            </a>
        </li>
        
        
        <li >
            <a href='/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        
        
        <li >
            <a href='/links/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5" />
  <path d="M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5" />
</svg>



                
                <span>Links</span>
            </a>
        </li>
        
        <li class="menu-bottom-section">
            <ol class="menu">
                    
                        <li id="i18n-switch">  
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M4 5h7" />
  <path d="M9 3v2c0 4.418 -2.239 8 -5 8" />
  <path d="M5 9c-.003 2.144 2.952 3.908 6.7 4" />
  <path d="M12 20l4 -9l4 9" />
  <path d="M19.1 18h-6.2" />
</svg>



                            <select name="language" title="language" onchange="window.location.href = this.selectedOptions[0].value">
                                
                                    <option value="https://blogbook.eu.org/en/" >English</option>
                                
                                    <option value="https://blogbook.eu.org/" selected>简体中文</option>
                                
                            </select>
                        </li>
                    
                

                
                    <li id="dark-mode-toggle">
                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <span>暗色模式</span>
                    </li>
                
            </ol>
        </li>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">目录</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#这个是关于我看李航的统计学习方法的一些记录以防我看完就忘">这个是关于我看李航的统计学习方法的一些记录,以防我看完就忘.</a></li>
    <li><a href="#第一章统计学习及监督学习概论">第一章统计学习及监督学习概论</a></li>
    <li><a href="#统计学习方法的三要素">统计学习方法的三要素</a></li>
    <li><a href="#过拟合与模型选择">过拟合与模型选择</a></li>
    <li><a href="#正则化与交叉验证">正则化与交叉验证</a></li>
    <li><a href="#感知机">感知机</a></li>
    <li><a href="#逻辑回归">逻辑回归</a>
      <ol>
        <li><a href="#1-逻辑回归的基本思想">1. 逻辑回归的基本思想</a></li>
        <li><a href="#2-逻辑回归的数学模型">2. 逻辑回归的数学模型</a>
          <ol>
            <li><a href="#21-sigmoid函数">2.1 Sigmoid函数</a></li>
            <li><a href="#22-逻辑回归模型">2.2 逻辑回归模型</a></li>
          </ol>
        </li>
        <li><a href="#3-几率odds与对数几率log-odds">3. 几率(Odds)与对数几率(Log-Odds)</a>
          <ol>
            <li><a href="#31-几率">3.1 几率</a></li>
            <li><a href="#32-对数几率logit">3.2 对数几率（Logit）</a></li>
          </ol>
        </li>
        <li><a href="#4-参数估计最大似然估计">4. 参数估计：最大似然估计</a>
          <ol>
            <li><a href="#41-似然函数">4.1 似然函数</a></li>
            <li><a href="#42-对数似然函数">4.2 对数似然函数</a></li>
            <li><a href="#43-梯度计算">4.3 梯度计算</a></li>
          </ol>
        </li>
        <li><a href="#5-损失函数交叉熵损失">5. 损失函数：交叉熵损失</a></li>
        <li><a href="#6-优化算法">6. 优化算法</a>
          <ol>
            <li><a href="#61-梯度下降法详细推导">6.1 梯度下降法详细推导</a></li>
            <li><a href="#62-牛顿法">6.2 牛顿法</a></li>
          </ol>
        </li>
        <li><a href="#7-逻辑回归的优缺点">7. 逻辑回归的优缺点</a>
          <ol>
            <li><a href="#71-优点">7.1 优点</a></li>
            <li><a href="#72-缺点">7.2 缺点</a></li>
          </ol>
        </li>
        <li><a href="#8-正则化逻辑回归">8. 正则化逻辑回归</a>
          <ol>
            <li><a href="#81-l1正则化lasso">8.1 L1正则化（Lasso）</a></li>
            <li><a href="#82-l2正则化ridge">8.2 L2正则化（Ridge）</a></li>
            <li><a href="#83-弹性网络elastic-net">8.3 弹性网络（Elastic Net）</a></li>
          </ol>
        </li>
        <li><a href="#9-多分类逻辑回归">9. 多分类逻辑回归</a>
          <ol>
            <li><a href="#91-一对一one-vs-one">9.1 一对一（One-vs-One）</a></li>
            <li><a href="#92-一对其余one-vs-rest">9.2 一对其余（One-vs-Rest）</a></li>
            <li><a href="#93-softmax回归多项逻辑回归">9.3 Softmax回归（多项逻辑回归）</a></li>
          </ol>
        </li>
        <li><a href="#10-模型评估指标">10. 模型评估指标</a></li>
        <li><a href="#11-实际应用场景">11. 实际应用场景</a></li>
        <li><a href="#12-与其他算法的比较">12. 与其他算法的比较</a></li>
        <li><a href="#13-总结">13. 总结</a></li>
      </ol>
    </li>
    <li><a href="#提升树">提升树</a></li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/ai/" >
                AI
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/p/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">统计学习方法</a>
        </h2>
    
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">2025-05-16</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    阅读时长: 9 分钟
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <h2 id="这个是关于我看李航的统计学习方法的一些记录以防我看完就忘">这个是关于我看李航的统计学习方法的一些记录,以防我看完就忘.
</h2><h2 id="第一章统计学习及监督学习概论">第一章统计学习及监督学习概论
</h2><ol>
<li>
<p>什么是统计学习</p>
<blockquote>
<p>就是基于数据建构一个概率统计模型并对数据进行一个预测.</p></blockquote>
</li>
<li>
<p>统计学习的对象</p>
<blockquote>
<p>其实就是数据,只不过这些数据的来源是多种多样的,比如文字,图像,视频,音频数据或者是它们的组合,关于数据的有一个基本假设就是迷人同类数据具有共同的性质的数据,比如说英文的文章,网页之类的.由于它们具有统计的规律性.所以可以用概率统计方法去处理它们.</p></blockquote>
</li>
</ol>
<h2 id="统计学习方法的三要素">统计学习方法的三要素
</h2><p>方法 = 模型+策略+算法</p>
<ol>
<li>
<p>模型
就是学习什么样的模型.其实就是模型的假设空间所包含的所有函数的集合.</p>
</li>
<li>
<p>策略
就是按照什么样的学习准则,也就是如何选择一个最佳模型.进而衍生出损失函数与风险函数预测的好坏..损失函数度量的是模型一次预测的好坏,风险函数度量平均意义下模型预测的好坏.</p>
</li>
<li>
<p>算法
指的就是学习模型的具体计算方法.统计学习基于训练数据集,根据学习策略,从假设空间中选择最优模型.也就是寻找最优解.</p>
</li>
</ol>
<h2 id="过拟合与模型选择">过拟合与模型选择
</h2><p>当假设空间有不同的复杂度(例如:不同参数个数)的模型的时候,就要面临模型选择问题,我们当然是希望选择一个或者学习一个合适的模型.如果当假设空间中存在着一个&quot;真&quot;模型时,那么选择或者学习的模型应当要逼近这个真实的模型,也就是模型的参数向量与真模型的参数向量相近.如果是一味提高对训练数据的预测能力,所选模型的复杂度往往会比真实模型来得要高,这种现象就称之为过拟合.</p>
<h2 id="正则化与交叉验证">正则化与交叉验证
</h2><p>交叉验证,随机将数据集分成三个部分,分别为训练集,验证集,测试集.训练集即为训练模型,验证集用于模型选择,测试用于对学习模型的评估.</p>
<h2 id="感知机">感知机
</h2><p>感知机的这个东西起源很早,在1957年就已经提出了,但是它的分类模型在大多数时候泛化能力不强,但是原理简单,但是它是学习神经网络和深度学习的一个起点.</p>
<ol>
<li>
<p>感知机的模型
感知机的模型思想很简单,就是用于一个分类问题,也就是说将一堆东西,简单的分成两类,我这里举一个例子就是比如说,在一个广场上站着很多人,然后我们拿一条直线将男人和女人分开,这里可能有人会问,如果找不到怎么办?这个也就是说这个类别是线性不可分的,也就是说感知机模型并不适用.感知机模型的使用的一大前提就是这个东西是线性可分的才行.这个也就极大限制了感知机的使用场景.</p>
<p>用数学的语言来说其实就是,有M个样本,每个样本对应着一个n维特征和一个二元输出,如下:
$(x_1^0,x_2^0,x_3^0,&hellip;,x_n^0,y_0),(x_1^1,x_2^1,x_3^1,&hellip;,x_n^1,y_1),&hellip;,到n$</p>
<p>我们的一个目标其实就是找到一个超平面,即:
$\theta_0+\theta_1x_1+&hellip;+\theta_nx_n = 0$
让其中的一个类别都满足$\theta_0+\theta_1x_1+&hellip;+\theta_nx_n&gt;0$
或让其中一个$&lt;0$,为了可以简化这种写法,我们其实可以加一个特征$x_0=1$,这样也就是$\sum_{i=0}^n\theta_ix_i=0$,其实用向量来表示就是$\theta \cdot x = 0$,而向量机的模型我们可以表示为, y = sign($\theta \cdot x$).
</p>
$$
sign(x) = 
\begin{cases}
-1 & x < 0 \\
1 & x \geq 0
\end{cases}
$$</li>
<li>
<p>感知机的损失函数
我们这个损失函数其实就是为了优化模型,感知机的损失函数它的优化目标就是期望使所有错误分类的样本到超平面的距离之和最小.</p>
</li>
</ol>
<h2 id="逻辑回归">逻辑回归
</h2><p>逻辑回归（Logistic Regression）是统计学习中的经典分类算法，虽然名字中有&quot;回归&quot;，但它实际上是一种分类方法。它通过logistic函数将线性回归的输出映射到(0,1)区间，从而实现概率预测。</p>
<h3 id="1-逻辑回归的基本思想">1. 逻辑回归的基本思想
</h3><p>逻辑回归的核心思想是：</p>
<ul>
<li>使用sigmoid函数将线性函数的输出映射到概率值</li>
<li>通过最大似然估计来求解参数</li>
<li>适用于二分类和多分类问题</li>
</ul>
<p>与线性回归不同，逻辑回归不是直接预测连续值，而是预测某个事件发生的概率。</p>
<h3 id="2-逻辑回归的数学模型">2. 逻辑回归的数学模型
</h3><h4 id="21-sigmoid函数">2.1 Sigmoid函数
</h4><p>Sigmoid函数（也称为logistic函数）定义为：
</p>
$$\sigma(z) = \frac{1}{1 + e^{-z}}$$<p>其中 $z = \theta_0 + \theta_1x_1 + \theta_2x_2 + &hellip; + \theta_nx_n = \theta^T x$</p>
<p>Sigmoid函数具有以下重要性质：</p>
<ul>
<li>函数值域为(0,1)，可以表示概率</li>
<li>单调递增</li>
<li>在z=0处，$\sigma(0) = 0.5$</li>
<li>当z→+∞时，$\sigma(z)→1$；当z→-∞时，$\sigma(z)→0$</li>
</ul>
<h4 id="22-逻辑回归模型">2.2 逻辑回归模型
</h4><p>对于二分类问题，逻辑回归模型表示为：
</p>
$$P(Y=1|x) = \frac{1}{1 + e^{-\theta^T x}}$$<p>
</p>
$$P(Y=0|x) = 1 - P(Y=1|x) = \frac{e^{-\theta^T x}}{1 + e^{-\theta^T x}}$$<h3 id="3-几率odds与对数几率log-odds">3. 几率(Odds)与对数几率(Log-Odds)
</h3><h4 id="31-几率">3.1 几率
</h4><p>几率定义为事件发生的概率与不发生概率的比值：
</p>
$$odds = \frac{P(Y=1|x)}{P(Y=0|x)} = \frac{P(Y=1|x)}{1-P(Y=1|x)}$$<h4 id="32-对数几率logit">3.2 对数几率（Logit）
</h4><p>对数几率是几率的对数：
</p>
$$logit(p) = \ln\left(\frac{p}{1-p}\right) = \theta^T x$$<p>这说明逻辑回归实际上是在对对数几率进行线性建模。</p>
<h3 id="4-参数估计最大似然估计">4. 参数估计：最大似然估计
</h3><h4 id="41-似然函数">4.1 似然函数
</h4><p>给定训练集 ${(x_i, y_i)}_{i=1}^m$，其中 $y_i \in {0,1}$，似然函数为：
</p>
$$L(\theta) = \prod_{i=1}^m P(y_i|x_i;\theta)$$<p>具体地：
</p>
$$L(\theta) = \prod_{i=1}^m [P(Y=1|x_i)]^{y_i} [P(Y=0|x_i)]^{1-y_i}$$<h4 id="42-对数似然函数">4.2 对数似然函数
</h4><p>取对数得到对数似然函数：
</p>
$$\ell(\theta) = \sum_{i=1}^m [y_i \log P(Y=1|x_i) + (1-y_i) \log P(Y=0|x_i)]$$<p>代入sigmoid函数：
</p>
$$\ell(\theta) = \sum_{i=1}^m [y_i \theta^T x_i - \log(1 + e^{\theta^T x_i})]$$<h4 id="43-梯度计算">4.3 梯度计算
</h4><p>对$\theta$求偏导：
</p>
$$\frac{\partial \ell(\theta)}{\partial \theta} = \sum_{i=1}^m (y_i - \sigma(\theta^T x_i))x_i$$<p>由于对数似然函数是凹函数，可以使用梯度上升法或牛顿法求解最优参数。</p>
<h3 id="5-损失函数交叉熵损失">5. 损失函数：交叉熵损失
</h3><p>逻辑回归的损失函数通常使用交叉熵损失（Cross-Entropy Loss）：
</p>
$$J(\theta) = -\frac{1}{m}\sum_{i=1}^m [y_i \log h_\theta(x_i) + (1-y_i) \log(1-h_\theta(x_i))]$$<p>其中 $h_\theta(x_i) = \sigma(\theta^T x_i)$ 是预测概率。</p>
<h3 id="6-优化算法">6. 优化算法
</h3><h4 id="61-梯度下降法详细推导">6.1 梯度下降法详细推导
</h4><p>梯度下降法是通过迭代优化来最小化损失函数的方法。下面详细推导逻辑回归中梯度下降的计算过程。</p>
<h5 id="611-损失函数回顾">6.1.1 损失函数回顾
</h5><p>逻辑回归的损失函数（交叉熵损失）为：
</p>
$$J(\theta) = -\frac{1}{m}\sum_{i=1}^m [y_i \log h_\theta(x_i) + (1-y_i) \log(1-h_\theta(x_i))]$$<p>其中：</p>
<ul>
<li>$h_\theta(x_i) = \sigma(\theta^T x_i) = \frac{1}{1 + e^{-\theta^T x_i}}$ 是预测概率</li>
<li>$m$ 是训练样本数量</li>
<li>$y_i \in {0,1}$ 是真实标签</li>
</ul>
<h5 id="612-梯度计算的详细推导">6.1.2 梯度计算的详细推导
</h5><p>我们需要计算 $\frac{\partial J(\theta)}{\partial \theta_j}$，其中 $\theta_j$ 是参数向量 $\theta$ 的第 $j$ 个分量。</p>
<p><strong>步骤1：单个样本的损失函数梯度</strong></p>
<p>对于单个样本 $(x_i, y_i)$，损失函数为：
</p>
$$J_i(\theta) = -[y_i \log h_\theta(x_i) + (1-y_i) \log(1-h_\theta(x_i))]$$<p>首先计算 $\frac{\partial h_\theta(x_i)}{\partial \theta_j}$：</p>
$$\frac{\partial h_\theta(x_i)}{\partial \theta_j} = \frac{\partial}{\partial \theta_j} \sigma(\theta^T x_i) = \frac{\partial}{\partial \theta_j} \frac{1}{1 + e^{-\theta^T x_i}}$$<p>使用链式法则：
</p>
$$\frac{\partial h_\theta(x_i)}{\partial \theta_j} = \frac{\partial \sigma(z)}{\partial z} \cdot \frac{\partial z}{\partial \theta_j}$$<p>其中 $z = \theta^T x_i$，所以 $\frac{\partial z}{\partial \theta_j} = x_{ij}$</p>
<p>Sigmoid函数的导数为：
</p>
$$\frac{\partial \sigma(z)}{\partial z} = \sigma(z)(1-\sigma(z)) = h_\theta(x_i)(1-h_\theta(x_i))$$<p>因此：
</p>
$$\frac{\partial h_\theta(x_i)}{\partial \theta_j} = h_\theta(x_i)(1-h_\theta(x_i)) \cdot x_{ij}$$<p><strong>步骤2：计算单个样本损失函数的梯度</strong></p>
$$\frac{\partial J_i(\theta)}{\partial \theta_j} = -\left[y_i \frac{1}{h_\theta(x_i)} \frac{\partial h_\theta(x_i)}{\partial \theta_j} + (1-y_i) \frac{1}{1-h_\theta(x_i)} \frac{\partial (1-h_\theta(x_i))}{\partial \theta_j}\right]$$<p>注意到：
</p>
$$\frac{\partial (1-h_\theta(x_i))}{\partial \theta_j} = -\frac{\partial h_\theta(x_i)}{\partial \theta_j}$$<p>代入得：
</p>
$$\frac{\partial J_i(\theta)}{\partial \theta_j} = -\left[y_i \frac{1}{h_\theta(x_i)} - (1-y_i) \frac{1}{1-h_\theta(x_i)}\right] \frac{\partial h_\theta(x_i)}{\partial \theta_j}$$$$= -\left[\frac{y_i}{h_\theta(x_i)} - \frac{1-y_i}{1-h_\theta(x_i)}\right] h_\theta(x_i)(1-h_\theta(x_i)) x_{ij}$$$$= -\left[y_i(1-h_\theta(x_i)) - (1-y_i)h_\theta(x_i)\right] x_{ij}$$$$= -[y_i - y_ih_\theta(x_i) - h_\theta(x_i) + y_ih_\theta(x_i)] x_{ij}$$$$= -[y_i - h_\theta(x_i)] x_{ij}$$$$= (h_\theta(x_i) - y_i) x_{ij}$$<p><strong>步骤3：整体损失函数的梯度</strong></p>
<p>对所有样本求平均：
</p>
$$\frac{\partial J(\theta)}{\partial \theta_j} = \frac{1}{m}\sum_{i=1}^m (h_\theta(x_i) - y_i) x_{ij}$$<p>用向量形式表示：
</p>
$$\frac{\partial J(\theta)}{\partial \theta} = \frac{1}{m} X^T (h_\theta(X) - y)$$<p>其中：</p>
<ul>
<li>$X$ 是 $m \times n$ 的特征矩阵</li>
<li>$h_\theta(X) = [\sigma(\theta^T x_1), \sigma(\theta^T x_2), &hellip;, \sigma(\theta^T x_m)]^T$</li>
<li>$y = [y_1, y_2, &hellip;, y_m]^T$</li>
</ul>
<h5 id="613-梯度下降更新规则">6.1.3 梯度下降更新规则
</h5><p>梯度下降的更新规则为：
</p>
$$\theta^{(t+1)} = \theta^{(t)} - \alpha \frac{\partial J(\theta^{(t)})}{\partial \theta}$$<p>具体地：
</p>
$$\theta^{(t+1)} = \theta^{(t)} - \frac{\alpha}{m} X^T (h_\theta(X) - y)$$<p>对于每个参数分量：
</p>
$$\theta_j^{(t+1)} = \theta_j^{(t)} - \frac{\alpha}{m} \sum_{i=1}^m (h_\theta(x_i) - y_i) x_{ij}$$<h5 id="614-算法流程">6.1.4 算法流程
</h5><ol>
<li><strong>初始化</strong>：随机初始化参数 $\theta^{(0)}$</li>
<li><strong>迭代更新</strong>：对于 $t = 0, 1, 2, &hellip;$
<ul>
<li>计算预测值：$h_\theta(x_i) = \sigma(\theta^T x_i)$</li>
<li>计算梯度：$\nabla J(\theta) = \frac{1}{m} X^T (h_\theta(X) - y)$</li>
<li>更新参数：$\theta^{(t+1)} = \theta^{(t)} - \alpha \nabla J(\theta^{(t)})$</li>
</ul>
</li>
<li><strong>收敛判断</strong>：当 $||\nabla J(\theta)||$ 小于阈值或达到最大迭代次数时停止</li>
</ol>
<h5 id="615-学习率的选择">6.1.5 学习率的选择
</h5><p>学习率 $\alpha$ 的选择非常重要：</p>
<ul>
<li><strong>太大</strong>：可能导致震荡，无法收敛</li>
<li><strong>太小</strong>：收敛速度很慢</li>
<li><strong>自适应学习率</strong>：随着迭代次数增加而减小</li>
</ul>
<p>常用的学习率策略：
</p>
$$\alpha^{(t)} = \frac{\alpha_0}{1 + \text{decay\_rate} \times t}$$<h5 id="616-梯度下降的几何解释">6.1.6 梯度下降的几何解释
</h5><p>从几何角度看，梯度 $\nabla J(\theta)$ 指向损失函数增长最快的方向，因此：</p>
<ul>
<li>负梯度方向 $-\nabla J(\theta)$ 是函数值下降最快的方向</li>
<li>梯度下降沿着负梯度方向移动，逐步找到最优解</li>
<li>步长由学习率 $\alpha$ 控制</li>
</ul>
<h4 id="62-牛顿法">6.2 牛顿法
</h4><p>利用二阶导数信息，收敛更快：
</p>
$$\theta := \theta - H^{-1} \nabla J(\theta)$$<p>其中 $H$ 是Hessian矩阵。</p>
<h3 id="7-逻辑回归的优缺点">7. 逻辑回归的优缺点
</h3><h4 id="71-优点">7.1 优点
</h4><ul>
<li><strong>模型简单</strong>：线性模型，易于理解和实现</li>
<li><strong>计算效率高</strong>：训练和预测速度快</li>
<li><strong>概率输出</strong>：直接给出分类概率，便于决策</li>
<li><strong>无需特征缩放</strong>：对特征尺度不敏感</li>
<li><strong>不需要调参</strong>：相对稳定，超参数较少</li>
</ul>
<h4 id="72-缺点">7.2 缺点
</h4><ul>
<li><strong>线性假设</strong>：只能处理线性可分问题</li>
<li><strong>对离群点敏感</strong>：极端值会影响模型性能</li>
<li><strong>特征工程要求高</strong>：需要人工构造有效特征</li>
<li><strong>多重共线性问题</strong>：特征间相关性影响模型稳定性</li>
</ul>
<h3 id="8-正则化逻辑回归">8. 正则化逻辑回归
</h3><p>为了防止过拟合，可以加入正则化项：</p>
<h4 id="81-l1正则化lasso">8.1 L1正则化（Lasso）
</h4>$$J(\theta) = -\frac{1}{m}\sum_{i=1}^m [y_i \log h_\theta(x_i) + (1-y_i) \log(1-h_\theta(x_i))] + \lambda \sum_{j=1}^n |\theta_j|$$<h4 id="82-l2正则化ridge">8.2 L2正则化（Ridge）
</h4>$$J(\theta) = -\frac{1}{m}\sum_{i=1}^m [y_i \log h_\theta(x_i) + (1-y_i) \log(1-h_\theta(x_i))] + \lambda \sum_{j=1}^n \theta_j^2$$<h4 id="83-弹性网络elastic-net">8.3 弹性网络（Elastic Net）
</h4><p>结合L1和L2正则化：
</p>
$$J(\theta) = -\frac{1}{m}\sum_{i=1}^m [y_i \log h_\theta(x_i) + (1-y_i) \log(1-h_\theta(x_i))] + \lambda_1 \sum_{j=1}^n |\theta_j| + \lambda_2 \sum_{j=1}^n \theta_j^2$$<h3 id="9-多分类逻辑回归">9. 多分类逻辑回归
</h3><h4 id="91-一对一one-vs-one">9.1 一对一（One-vs-One）
</h4><p>对于K个类别，训练$\frac{K(K-1)}{2}$个二分类器。</p>
<h4 id="92-一对其余one-vs-rest">9.2 一对其余（One-vs-Rest）
</h4><p>对于K个类别，训练K个二分类器，每个分类器区分一个类别与其他所有类别。</p>
<h4 id="93-softmax回归多项逻辑回归">9.3 Softmax回归（多项逻辑回归）
</h4><p>直接扩展到多分类：
</p>
$$P(Y=k|x) = \frac{e^{\theta_k^T x}}{\sum_{j=1}^K e^{\theta_j^T x}}$$<h3 id="10-模型评估指标">10. 模型评估指标
</h3><ul>
<li><strong>准确率（Accuracy）</strong>：正确预测的比例</li>
<li><strong>精确率（Precision）</strong>：预测为正例中实际为正例的比例</li>
<li><strong>召回率（Recall）</strong>：实际正例中被正确预测的比例</li>
<li><strong>F1-Score</strong>：精确率和召回率的调和平均</li>
<li><strong>AUC-ROC</strong>：ROC曲线下的面积</li>
<li><strong>对数损失（Log Loss）</strong>：衡量概率预测的质量</li>
</ul>
<h3 id="11-实际应用场景">11. 实际应用场景
</h3><ul>
<li><strong>医疗诊断</strong>：根据症状预测疾病概率</li>
<li><strong>金融风控</strong>：信用评分，违约概率预测</li>
<li><strong>市场营销</strong>：客户响应率预测</li>
<li><strong>推荐系统</strong>：用户点击率预测</li>
<li><strong>文本分类</strong>：垃圾邮件检测</li>
<li><strong>图像识别</strong>：简单的二分类任务</li>
</ul>
<h3 id="12-与其他算法的比较">12. 与其他算法的比较
</h3><div class="table-wrapper"><table>
  <thead>
      <tr>
          <th>特征</th>
          <th>逻辑回归</th>
          <th>线性回归</th>
          <th>SVM</th>
          <th>决策树</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>输出类型</td>
          <td>概率</td>
          <td>连续值</td>
          <td>分类/回归</td>
          <td>分类/回归</td>
      </tr>
      <tr>
          <td>模型复杂度</td>
          <td>低</td>
          <td>低</td>
          <td>中等</td>
          <td>高</td>
      </tr>
      <tr>
          <td>可解释性</td>
          <td>强</td>
          <td>强</td>
          <td>中等</td>
          <td>强</td>
      </tr>
      <tr>
          <td>处理非线性</td>
          <td>弱</td>
          <td>弱</td>
          <td>强（核函数）</td>
          <td>强</td>
      </tr>
      <tr>
          <td>训练速度</td>
          <td>快</td>
          <td>快</td>
          <td>中等</td>
          <td>快</td>
      </tr>
  </tbody>
</table></div>
<h3 id="13-总结">13. 总结
</h3><p>逻辑回归是机器学习中的基础且重要的算法，具有以下关键特点：</p>
<ol>
<li><strong>数学基础扎实</strong>：基于最大似然估计，理论完备</li>
<li><strong>实现简单</strong>：模型结构清晰，易于编程实现</li>
<li><strong>应用广泛</strong>：在工业界有大量实际应用</li>
<li><strong>可解释性强</strong>：参数具有明确的物理意义</li>
<li><strong>计算效率高</strong>：训练和预测速度快</li>
</ol>
<p>虽然逻辑回归在处理复杂非线性问题时有局限性，但它仍然是分类问题的首选baseline算法，也是理解更复杂机器学习算法的重要基础。</p>
<h2 id="提升树">提升树
</h2>
</section>


    <footer class="article-footer">
    

    <section class="article-lastmod">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



        <span>
            最后更新于 2025-06-16 12:55
        </span>
    </section></footer>


    
</article>

    

    

<aside class="related-content--wrapper">
    <h2 class="section-title">相关文章</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="">
    <a href="/p/%E5%9B%BE%E5%83%8F%E5%88%B0%E5%9B%BE%E5%83%8F%E7%9A%84%E7%BF%BB%E8%AF%91%E7%9A%84%E5%85%B7%E6%9C%89%E8%87%AA%E9%80%82%E5%BA%94%E5%AE%9E%E4%BE%8B%E5%BD%92%E4%B8%80%E5%8C%96%E7%9A%84%E6%97%A0%E7%9B%91%E7%9D%A3%E7%94%9F%E6%88%90%E6%B3%A8%E6%84%8F%E7%BD%91%E7%BB%9C/">
        
        

        <div class="article-details">
            <h2 class="article-title">图像到图像的翻译的具有自适应实例归一化的无监督生成注意网络</h2>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/p/%E5%8D%B7%E7%A7%AF%E5%85%AC%E5%BC%8F/">
        
        

        <div class="article-details">
            <h2 class="article-title">卷积公式</h2>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
        2025 云雾中的山-NubisMons
    </section>
    
    <section class="powerby">
        使用 <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> 构建 <br />
        主题 <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.30.0">Stack</a></b> 由 <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a> 设计
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
